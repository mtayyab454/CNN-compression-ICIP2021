Wed Jan 12 14:44:51 EST 2022
Slurm nodes: evc1
You were assigned 1 gpu(s)
Please run `conda env list` to see a list of all available environments. Use
`source activate <env>` to activate the environment '<env>'. 

Currently Loaded Modules:
  1) anaconda/anaconda3

 

	[4mGPU0	mlx5_0	CPU Affinity	NUMA Affinity[0m
GPU0	 X 	SYS	0,2,4,6	0-1
mlx5_0	SYS	 X 		

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks


compress_rate: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 13, 6, 8, 6, 6, 6, 12, 15, 15, 6, 15, 6, 12, 6, 12, 6, 10, 6, 8, 6, 18, 6, 12, 6, 26, 26, 26, 10, 23, 10, 23, 13, 23, 10, 20, 7, 23, 10, 16, 7, 13, 7]
Namespace(add_bn=True, arch='resnet56', checkpoint='cifar/checkpoint', compress_rate=[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 13, 6, 8, 6, 6, 6, 12, 15, 15, 6, 15, 6, 12, 6, 12, 6, 10, 6, 8, 6, 18, 6, 12, 6, 26, 26, 26, 10, 23, 10, 23, 13, 23, 10, 20, 7, 23, 10, 16, 7, 13, 7], dataset='cifar10', epochs=120, gamma=0.1, jobid='122969', l1_weight=0, l2_weight=0.001, logs='cifar/logs', lr=0.01, manualSeed=535, momentum=0.9, schedule=[30, 60, 90], test_batch=100, train_batch=128, weight_decay=0.0005, workers=4)
Processing conv  0
Processing conv  1
Processing conv  2
Processing conv  3
Processing conv  4
Processing conv  5
Processing conv  6
Processing conv  7
Processing conv  8
Processing conv  9
Processing conv  10
Processing conv  11
Processing conv  12
Processing conv  13
Processing conv  14
Processing conv  15
Processing conv  16
Processing conv  17
Processing conv  18
Processing conv  19
Processing conv  20
Processing conv  21
Processing conv  22
Processing conv  23
Processing conv  24
Processing conv  25
Processing conv  26
Processing conv  27
Processing conv  28
Processing conv  29
Processing conv  30
Processing conv  31
Processing conv  32
Processing conv  33
Processing conv  34
Processing conv  35
Processing conv  36
Processing conv  37
Processing conv  38
Processing conv  39
Processing conv  40
Processing conv  41
Processing conv  42
Processing conv  43
Processing conv  44
Processing conv  45
Processing conv  46
Processing conv  47
Processing conv  48
Processing conv  49
Processing conv  50
Processing conv  51
Processing conv  52
Processing conv  53
Processing conv  54
Skipping linear  55
update_channels: Model compression is updated to [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 13, 6, 8, 6, 6, 6, 12, 15, 15, 6, 15, 6, 12, 6, 12, 6, 10, 6, 8, 6, 18, 6, 12, 6, 26, 26, 26, 10, 23, 10, 23, 13, 23, 10, 20, 7, 23, 10, 16, 7, 13, 7]

############################################# resnet56-cifar10 #############################################

    Model FLOPs: 250.97M
    Basis Model FLOPs: 90.03M
    % Reduction in FLOPs: 64.13 %
    % Speedup: 2.79 %

    Model Conv Params: 0.85M
    Basis Model Conv params: 0.26M
    % Reduction in Conv params: 69.59 %

    Model Total Params: 0.85M
    Basis Model Total params: 0.26M
    % Reduction in Total params: 69.54 %

    Model Filters: 2032
    Basis Model Filters: 593
    % Reduction in Filters: 70.82 %

    Model Accuracy: 
    Basis Model Accuracy: 
    Reduction in Accuracy: 

    Filter in original convs: [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64]
    Filter in original basis convs: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 13, 6, 8, 6, 6, 6, 12, 15, 15, 6, 15, 6, 12, 6, 12, 6, 10, 6, 8, 6, 18, 6, 12, 6, 26, 26, 26, 10, 23, 10, 23, 13, 23, 10, 20, 7, 23, 10, 16, 7, 13, 7]

#########################################################################################################

==> Preparing dataset cifar10
Files already downloaded and verified
Testing...
 -> Progress: 20 done!
 -> Progress: 40 done!
 -> Progress: 60 done!
 -> Progress: 80 done!
 -> Progress: 100 done!

Test loss: 5.9633 
Val accuracy: 10.00%
==> Preparing dataset cifar10
Files already downloaded and verified
==> Preparing dataset cifar10
Files already downloaded and verified
    Total params: 0.26M

Epoch: [1 | 90] LR: 0.010000
Training...
 -> Progress: 20 done!
 -> Progress: 40 done!
 -> Progress: 60 done!
 -> Progress: 80 done!
 -> Progress: 100 done!
Testing...
 -> Progress: 20 done!
 -> Progress: 40 done!
 -> Progress: 60 done!
 -> Progress: 80 done!
 -> Progress: 100 done!
Traceback (most recent call last):
  File "run_cifar.py", line 124, in <module>
    main()
  File "run_cifar.py", line 121, in main
    loss_weights=[args.l1_weight, args.l2_weight], dataset_name=args.dataset, args=args, save_best=True)
  File "/lustre/fs0/home/mtayyab/codes/CNN-compression-ICIP2021/cifar/trainer.py", line 107, in training_loop
    torch.save(model.state_dict(), os.path.join('checkpoint', logger.fname, logger.fname + '.pth'))
  File "/apps/anaconda/anaconda3/envs/pytorch-gpu/lib/python3.6/site-packages/torch/serialization.py", line 224, in save
    return _with_file_like(f, "wb", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File "/apps/anaconda/anaconda3/envs/pytorch-gpu/lib/python3.6/site-packages/torch/serialization.py", line 147, in _with_file_like
    f = open(f, mode)
FileNotFoundError: [Errno 2] No such file or directory: 'checkpoint/122969_resnet56/122969_resnet56.pth'

real	0m37.153s
user	0m39.508s
sys	0m6.055s

Ending script...
Wed Jan 12 14:45:30 EST 2022
